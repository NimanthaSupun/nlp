{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ba26b6-42b9-400a-b7f6-e3264a3f3bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3413615a-21e0-4d8c-ad8e-6444edd3829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Thor eating pizza, Loki is eating pizza, Ironman ate pizza already\",\n",
    "    \"Apple is announcing new iphone tomorrow\",\n",
    "    \"Tesla is announcing new model-3 tomorrow\",\n",
    "    \"Google is announcing new pixel-6 tomorrow\",\n",
    "    \"Microsoft is announcing new surface tomorrow\",\n",
    "    \"Amazon is announcing new eco-dot tomorrow\",\n",
    "    \"I am eating biryani and you are eating grapes\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d6306df-e264-4f45-9aca-6db9ca113b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer()\n",
    "transform_output = v.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fdd8def-9f9b-4ebd-8254-39a37c2ecd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thor': 25, 'eating': 10, 'pizza': 22, 'loki': 17, 'is': 16, 'ironman': 15, 'ate': 7, 'already': 0, 'apple': 5, 'announcing': 4, 'new': 20, 'iphone': 14, 'tomorrow': 26, 'tesla': 24, 'model': 19, 'google': 12, 'pixel': 21, 'microsoft': 18, 'surface': 23, 'amazon': 2, 'eco': 11, 'dot': 9, 'am': 1, 'biryani': 8, 'and': 3, 'you': 27, 'are': 6, 'grapes': 13}\n"
     ]
    }
   ],
   "source": [
    "print(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b3dff57-1f51-43b6-bf45-1af37fb6aed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_CountVectorizer__metadata_request__fit',\n",
       " '_CountVectorizer__metadata_request__transform',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__sklearn_tags__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_build_request_for_signature',\n",
       " '_char_ngrams',\n",
       " '_char_wb_ngrams',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_params',\n",
       " '_check_stop_words_consistency',\n",
       " '_check_vocabulary',\n",
       " '_count_vocab',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_limit_features',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sort_features',\n",
       " '_stop_words_id',\n",
       " '_tfidf',\n",
       " '_validate_data',\n",
       " '_validate_ngram_range',\n",
       " '_validate_params',\n",
       " '_validate_vocabulary',\n",
       " '_warn_for_unused_params',\n",
       " '_white_spaces',\n",
       " '_word_ngrams',\n",
       " 'analyzer',\n",
       " 'binary',\n",
       " 'build_analyzer',\n",
       " 'build_preprocessor',\n",
       " 'build_tokenizer',\n",
       " 'decode',\n",
       " 'decode_error',\n",
       " 'dtype',\n",
       " 'encoding',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'fixed_vocabulary_',\n",
       " 'get_feature_names_out',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'get_stop_words',\n",
       " 'idf_',\n",
       " 'input',\n",
       " 'inverse_transform',\n",
       " 'lowercase',\n",
       " 'max_df',\n",
       " 'max_features',\n",
       " 'min_df',\n",
       " 'ngram_range',\n",
       " 'norm',\n",
       " 'preprocessor',\n",
       " 'set_params',\n",
       " 'smooth_idf',\n",
       " 'stop_words',\n",
       " 'strip_accents',\n",
       " 'sublinear_tf',\n",
       " 'token_pattern',\n",
       " 'tokenizer',\n",
       " 'transform',\n",
       " 'use_idf',\n",
       " 'vocabulary',\n",
       " 'vocabulary_']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba16f0c-96d7-4185-b5f6-ce860ad7db03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['already', 'am', 'amazon', 'and', 'announcing', 'apple', 'are',\n",
       "       'ate', 'biryani', 'dot', 'eating', 'eco', 'google', 'grapes',\n",
       "       'iphone', 'ironman', 'is', 'loki', 'microsoft', 'model', 'new',\n",
       "       'pixel', 'pizza', 'surface', 'tesla', 'thor', 'tomorrow', 'you'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc9c038-625b-48a5-9e4d-10dc4678641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already              |    2.386294361119891\n",
      "am                   |    2.386294361119891\n",
      "amazon               |    2.386294361119891\n",
      "and                  |    2.386294361119891\n",
      "announcing           |   1.2876820724517808\n",
      "apple                |    2.386294361119891\n",
      "are                  |    2.386294361119891\n",
      "ate                  |    2.386294361119891\n",
      "biryani              |    2.386294361119891\n",
      "dot                  |    2.386294361119891\n",
      "eating               |   1.9808292530117262\n",
      "eco                  |    2.386294361119891\n",
      "google               |    2.386294361119891\n",
      "grapes               |    2.386294361119891\n",
      "iphone               |    2.386294361119891\n",
      "ironman              |    2.386294361119891\n",
      "is                   |   1.1335313926245225\n",
      "loki                 |    2.386294361119891\n",
      "microsoft            |    2.386294361119891\n",
      "model                |    2.386294361119891\n",
      "new                  |   1.2876820724517808\n",
      "pixel                |    2.386294361119891\n",
      "pizza                |    2.386294361119891\n",
      "surface              |    2.386294361119891\n",
      "tesla                |    2.386294361119891\n",
      "thor                 |    2.386294361119891\n",
      "tomorrow             |   1.2876820724517808\n",
      "you                  |    2.386294361119891\n"
     ]
    }
   ],
   "source": [
    "names = v.get_feature_names_out()\n",
    "for word in names:\n",
    "    idx = v.vocabulary_.get(word)\n",
    "    print('{:20} | {:20}'.format(word,v.idf_[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481a99e-2207-414e-a680-b0d2f0f1074c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tensorflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
